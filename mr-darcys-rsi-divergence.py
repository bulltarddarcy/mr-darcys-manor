import streamlit as st
import pandas as pd
import numpy as np
import requests
import re
from io import StringIO
from datetime import datetime, timedelta

# --- Secrets & Path Configuration ---
def get_confirmed_gdrive_data(url_or_id, is_id=False):
    """Bypasses the 'File too large to scan' warning page using a token handshake."""
    try:
        file_id = url_or_id
        if not is_id:
            if 'id=' in url_or_id: 
                file_id = url_or_id.split('id=')[1].split('&')[0]
            elif '/d/' in url_or_id: 
                file_id = url_or_id.split('/d/')[1].split('/')[0]
        
        download_url = f"https://docs.google.com/uc?export=download&id={file_id}"
        session = requests.Session()
        response = session.get(download_url, params={'id': file_id}, stream=True)
        
        confirm_token = None
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                confirm_token = value
                break
        
        if not confirm_token:
            match = re.search(r'confirm=([0-9A-Za-z_]+)', response.text)
            if match: confirm_token = match.group(1)

        if confirm_token:
            response = session.get(download_url, params={'id': file_id, 'confirm': confirm_token}, stream=True)
        
        if response.text.strip().startswith("<!DOCTYPE html>"): return None
            
        return StringIO(response.text)
    except Exception as e:
        return None

@st.cache_data(ttl=3600)
def fetch_ticker_map():
    """Reads the Ticker -> FileID mapping file generated by the Apps Script."""
    if "URL_TICKER_MAP" not in st.secrets:
        return {}
    buffer = get_confirmed_gdrive_data(st.secrets["URL_TICKER_MAP"])
    if buffer:
        try:
            # Assumes CSV format: TICKER,FILE_ID
            df_map = pd.read_csv(buffer, names=['Ticker', 'FileID'], header=None)
            return dict(zip(df_map['Ticker'].str.strip().upper(), df_map['FileID'].str.strip()))
        except: return {}
    return {}

def load_dataset_config():
    """Reads the configuration for master datasets."""
    try:
        if "URL_CONFIG" not in st.secrets:
            return {"Darcy Data": "URL_DARCY", "S&P 100 Data": "URL_SP100"}
        config_url = st.secrets["URL_CONFIG"]
        buffer = get_confirmed_gdrive_data(config_url)
        if buffer:
            lines = buffer.getvalue().splitlines()
            return {line.split(',')[0].strip(): line.split(',')[1].strip() for line in lines if ',' in line}
    except: pass
    return {"Darcy Data": "URL_DARCY"}

# --- Logic Constants ---
VOL_SMA_PERIOD = 30
DIVERGENCE_LOOKBACK = 90
SIGNAL_LOOKBACK_PERIOD = 25
RSI_DIFF_THRESHOLD = 2
EMA8_PERIOD = 8
EMA21_PERIOD = 21
EV_LOOKBACK_YEARS = 10
MIN_N_THRESHOLD = 5

# --- Streamlit UI Setup ---
st.set_page_config(page_title="RSI Divergence Scanner", layout="wide")

st.markdown("""
    <style>
    .top-note { color: #888888; font-size: 14px; margin-bottom: 2px; font-family: inherit; }
    table { width: 100%; border-collapse: collapse; table-layout: fixed; margin-bottom: 2rem; }
    thead tr th { background-color: #f0f2f6 !important; color: #31333f !important; padding: 12px !important; border-bottom: 2px solid #dee2e6; }
    th:nth-child(1) { width: 8%; } th:nth-child(2) { width: 22%; } th:nth-child(3) { width: 10%; } th:nth-child(4) { width: 10%; } 
    th:nth-child(5) { width: 8%; } th:nth-child(6) { width: 10%; } th:nth-child(7) { width: 10%; } th:nth-child(8) { width: 11%; } th:nth-child(9) { width: 11%; } 
    tbody tr td { padding: 10px !important; border-bottom: 1px solid #eee; word-wrap: break-word; font-size: 14px; }
    .align-left { text-align: left !important; } .align-center { text-align: center !important; }
    .ev-positive { background-color: #e6f4ea !important; color: #1e7e34; font-weight: 500; }
    .ev-negative { background-color: #fce8e6 !important; color: #c5221f; font-weight: 500; }
    .ev-neutral { color: #5f6368; }
    .tag-bubble { display: inline-block; padding: 2px 10px; border-radius: 12px; font-size: 12px; font-weight: 600; margin: 2px 4px 2px 0; color: white; white-space: nowrap; }
    .footer-header { color: #31333f; margin-top: 1.5rem; border-bottom: 1px solid #ddd; padding-bottom: 5px; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

st.title("üìà RSI Divergence Scanner")

# --- EV Calculation Logic ---
def calculate_ev_from_long_history(ticker, timeframe, target_rsi, current_price, t_map):
    """Calculates EV using 10 years of data from unique ticker files."""
    if ticker not in t_map: return None
    
    buffer = get_confirmed_gdrive_data(t_map[ticker], is_id=True)
    if not buffer: return None
    
    long_df = pd.read_csv(buffer)
    long_df.columns = [c.strip().upper() for c in long_df.columns]
    date_col = next((c for c in long_df.columns if 'DATE' in c), None)
    if not date_col: return None
    
    long_df[date_col] = pd.to_datetime(long_df[date_col])
    long_df = long_df.set_index(date_col).sort_index()

    p_col, r_col = ('W_CLOSE', 'W_RSI_14') if timeframe == 'Weekly' else ('CLOSE', 'RSI_14')
    if p_col not in long_df.columns or r_col not in long_df.columns: return None

    cutoff_date = long_df.index.max() - pd.DateOffset(years=EV_LOOKBACK_YEARS)
    hist_pool = long_df[(long_df.index >= cutoff_date) & (long_df.index < long_df.index.max())].copy()
    mask = (hist_pool[r_col] >= target_rsi - 2) & (hist_pool[r_col] <= target_rsi + 2)
    match_indices = np.where(mask)[0]
    
    returns_30, returns_90 = [], []
    for idx_pos in match_indices:
        abs_idx = long_df.index.get_loc(hist_pool.index[idx_pos])
        if abs_idx + 30 < len(long_df):
            returns_30.append((long_df.iloc[abs_idx + 30][p_col] - long_df.iloc[abs_idx][p_col]) / long_df.iloc[abs_idx][p_col])
        if abs_idx + 90 < len(long_df):
            returns_90.append((long_df.iloc[abs_idx + 90][p_col] - long_df.iloc[abs_idx][p_col]) / long_df.iloc[abs_idx][p_col])

    results = {}
    for r_list, key in [(returns_30, 'ev30'), (returns_90, 'ev90')]:
        if len(r_list) >= MIN_N_THRESHOLD:
            avg_ret = np.mean(r_list)
            results[key] = {"price": current_price * (1 + avg_ret), "n": len(r_list), "return": avg_ret}
        else: results[key] = None
    return results

# --- Helpers ---
def style_tags(tag_str):
    if not tag_str: return ''
    tags = tag_str.split(", ")
    colors = {f"EMA{EMA8_PERIOD}": "#4a90e2", f"EMA{EMA21_PERIOD}": "#9b59b6", "VOL_HIGH": "#e67e22", "V_GROW": "#27ae60"}
    html_str = ''
    for t in tags:
        color = colors.get(t, "#7f8c8d")
        html_str += f'<span class="tag-bubble" style="background-color: {color};">{t}</span>'
    return html_str

def prepare_data(df):
    df.columns = [col.strip().upper() for col in df.columns]
    date_col = next((c for c in df.columns if 'DATE' in c), None)
    if not date_col: return None, None
    df[date_col] = pd.to_datetime(df[date_col])
    df = df.set_index(date_col).sort_index()
    
    df_d = df.copy()
    df_d.rename(columns={'CLOSE': 'Price', 'VOLUME': 'Volume', 'HIGH': 'High', 'LOW': 'Low', 'RSI_14': 'RSI', 'EMA_8': 'EMA8', 'EMA_21': 'EMA21'}, inplace=True)
    df_d['VolSMA'] = df_d['Volume'].rolling(window=VOL_SMA_PERIOD).mean()
    df_d = df_d.dropna(subset=['Price', 'RSI'])
    
    if 'W_CLOSE' in df.columns:
        df_w = df.copy()
        df_w.rename(columns={'W_CLOSE': 'Price', 'W_VOLUME': 'Volume', 'W_HIGH': 'High', 'W_LOW': 'Low', 'W_RSI_14': 'RSI', 'W_EMA_8': 'EMA8', 'W_EMA_21': 'EMA21'}, inplace=True)
        df_w['VolSMA'] = df_w['Volume'].rolling(window=VOL_SMA_PERIOD).mean()
        df_w['ChartDate'] = df_w.index - pd.Timedelta(days=4)
        df_w = df_w.dropna(subset=['Price', 'RSI'])
    else: df_w = None
    return df_d, df_w

def find_divergences(df_tf, ticker, timeframe, t_map):
    divergences = []
    if len(df_tf) < DIVERGENCE_LOOKBACK + 1: return divergences
    latest_p = df_tf.iloc[-1]
    
    # Statistical analysis enrichment via unique 10-year files
    ev_data = calculate_ev_from_long_history(ticker, timeframe, latest_p['RSI'], latest_p['Price'], t_map)

    def get_date_str(p): return df_tf.loc[p.name, 'ChartDate'].strftime('%Y-%m-%d') if timeframe == 'Weekly' else p.name.strftime('%Y-%m-%d')
    start_idx = max(DIVERGENCE_LOOKBACK, len(df_tf) - SIGNAL_LOOKBACK_PERIOD)
    
    for i in range(start_idx, len(df_tf)):
        p2 = df_tf.iloc[i]
        lookback = df_tf.iloc[i - DIVERGENCE_LOOKBACK : i]
        for s_type in ['Bullish', 'Bearish']:
            trigger = False
            if s_type == 'Bullish' and p2['Low'] < lookback['Low'].min():
                p1 = lookback.loc[lookback['RSI'].idxmin()]
                if p2['RSI'] > (p1['RSI'] + RSI_DIFF_THRESHOLD) and not (df_tf.loc[p1.name : p2.name, 'RSI'] > 50).any(): trigger = True
            elif s_type == 'Bearish' and p2['High'] > lookback['High'].max():
                p1 = lookback.loc[lookback['RSI'].idxmax()]
                if p2['RSI'] < (p1['RSI'] - RSI_DIFF_THRESHOLD) and not (df_tf.loc[p1.name : p2.name, 'RSI'] < 50).any(): trigger = True
            
            if trigger:
                tags = []
                if s_type == 'Bullish':
                    if latest_p['Price'] >= latest_p.get('EMA8', 0): tags.append(f"EMA{EMA8_PERIOD}")
                else:
                    if latest_p['Price'] <= latest_p.get('EMA8', 99999): tags.append(f"EMA{EMA8_PERIOD}")
                
                divergences.append({
                    'Ticker': ticker, 'Type': s_type, 'Timeframe': timeframe, 'Tags': ", ".join(tags),
                    'P1 Date': get_date_str(p1), 'Signal Date': get_date_str(p2),
                    'RSI': f"{int(round(p1['RSI']))} ‚Üí {int(round(p2['RSI']))}",
                    'P1 Price': f"${p1['Low' if s_type=='Bullish' else 'High']:,.2f}", 
                    'P2 Price': f"${p2['Low' if s_type=='Bullish' else 'High']:,.2f}",
                    'ev30_raw': ev_data.get('ev30') if ev_data else None,
                    'ev90_raw': ev_data.get('ev90') if ev_data else None
                })
    return divergences

# --- App Logic ---
t_map = fetch_ticker_map()
dataset_map = load_dataset_config()
data_option = st.pills("Select Dataset", options=list(dataset_map.keys()), selection_mode="single", default=list(dataset_map.keys())[0])

if data_option:
    target_url = st.secrets[dataset_map[data_option]]
    csv_buffer = get_confirmed_gdrive_data(target_url)
    if csv_buffer:
        master = pd.read_csv(csv_buffer)
        t_col = next((c for c in master.columns if c.strip().upper() in ['TICKER', 'SYMBOL']), None)
        date_col = next((col for col in master.columns if 'DATE' in col.upper()), None)
        last_updated_str = pd.to_datetime(master[date_col]).max().strftime('%Y-%m-%d') if date_col else "Unknown"
        
        st.markdown(f'<div class="top-note">‚ÑπÔ∏è See bottom of page for strategy logic and tag explanations.</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="top-note">üìÖ Last Updated: {last_updated_str}</div>', unsafe_allow_html=True)

        raw_results = []
        progress_bar = st.progress(0, text="Scanning Signals...")
        grouped = master.groupby(t_col)
        for i, (ticker, group) in enumerate(grouped):
            d_d, d_w = prepare_data(group.copy())
            if d_d is not None: raw_results.extend(find_divergences(d_d, ticker, 'Daily', t_map))
            if d_w is not None: raw_results.extend(find_divergences(d_w, ticker, 'Weekly', t_map))
            progress_bar.progress((i + 1) / len(grouped))

        if raw_results:
            res_df = pd.DataFrame(raw_results)
            consolidated = res_df.groupby(['Ticker', 'Type', 'Timeframe']).head(1)
            for tf in ['Daily', 'Weekly']:
                st.divider()
                st.header(f"üìÖ {tf} Divergence Analysis")
                for s_type, emoji in [('Bullish', 'üü¢'), ('Bearish', 'üî¥')]:
                    tbl_df = consolidated[(consolidated['Type']==s_type) & (consolidated['Timeframe']==tf)].copy()
                    if not tbl_df.empty:
                        st.subheader(f"{emoji} {s_type} Signals")
                        html = '<table><thead><tr><th>Ticker</th><th>Tags</th><th>P1 Date</th><th>Signal Date</th><th>RSI</th><th>P1 Price</th><th>P2 Price</th><th>EV 30p</th><th>EV 90p</th></tr></thead><tbody>'
                        for _, row in tbl_df.iterrows():
                            html += f'<tr><td class="align-left"><b>{row["Ticker"]}</b></td><td class="align-left">{style_tags(row["Tags"])}</td>'
                            html += f'<td class="align-center">{row["P1 Date"]}</td><td class="align-center">{row["Signal Date"]}</td>'
                            html += f'<td class="align-center">{row["RSI"]}</td><td class="align-left">{row["P1 Price"]}</td><td class="align-left">{row["P2 Price"]}</td>'
                            for ev_key in ['ev30_raw', 'ev90_raw']:
                                data = row[ev_key]
                                if data:
                                    is_pos = data['return'] > 0
                                    cls = ("ev-positive" if is_pos else "ev-negative") if s_type == 'Bullish' else ("ev-positive" if not is_pos else "ev-negative")
                                    html += f'<td class="{cls}">{data["return"]*100:+.1f}% <br><small>(${data["price"]:,.2f}, N={data["n"]})</small></td>'
                                else: html += '<td class="ev-neutral">N/A</td>'
                            html += '</tr>'
                        html += '</tbody></table>'
                        st.markdown(html, unsafe_allow_html=True)
            
            # --- Robust Footer ---
            st.divider()
            f_col1, f_col2, f_col3 = st.columns(3)
            with f_col1:
                st.markdown('<div class="footer-header">üìâ SIGNAL LOGIC</div>', unsafe_allow_html=True)
                st.markdown(f"""
                * **Dataset Lookback**: Divergence signals are identified using a high-performance **3-year historical dataset**.
                * **Mechanism**: Compares RSI at a new extreme to a previous extreme within a **{DIVERGENCE_LOOKBACK}-period window**.
                """)
            with f_col2:
                st.markdown('<div class="footer-header">üîÆ EV ANALYSIS</div>', unsafe_allow_html=True)
                st.markdown(f"""
                * **Extended Data**: EV calculations utilize the **full 10-year historical record** from unique ticker files.
                * **Methodology**: Averages the returns of matching RSI occurrences within **¬±2 points** of the current level.
                """)
            with f_col3:
                st.markdown('<div class="footer-header">üè∑Ô∏è TECHNICAL TAGS</div>', unsafe_allow_html=True)
                st.markdown(f"""
                * **EMA Filters**: Tags based on price relative to **EMA{EMA8_PERIOD}** and **EMA{EMA21_PERIOD}**.
                * **Volume**: Indicators for **VOL_HIGH** and **V_GROW**.
                """)
